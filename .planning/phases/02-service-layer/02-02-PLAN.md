---
phase: 02-service-layer
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - backend/app/service_scicrunch.py
autonomous: true
requirements:
  - CACHE-01
  - CACHE-02
  - CACHE-03

must_haves:
  truths:
    - "resolve_rrid fetches metadata from scicrunch.org resolver and returns normalized subset"
    - "Resolved metadata is cached in the DocidRrid row's resolved_json JSONB column after first resolve"
    - "Subsequent resolve calls reuse cached data if last_resolved_at is less than 30 days old"
    - "resolved_json stores only normalized subset (name, rrid, description, url, resource_type, properCitation, mentions) not the raw blob"
    - "On SciCrunch API failure, stale cached data is returned if available; error only if no cache exists"
  artifacts:
    - path: "backend/app/service_scicrunch.py"
      provides: "Resolver function with cache logic"
      exports: ["resolve_rrid"]
      contains: "SCICRUNCH_RESOLVER_BASE"
  key_links:
    - from: "backend/app/service_scicrunch.py"
      to: "scicrunch.org"
      via: "requests.Session GET to resolver URL"
      pattern: "SCICRUNCH_RESOLVER_BASE"
    - from: "backend/app/service_scicrunch.py"
      to: "backend/app/models.py"
      via: "DocidRrid model for cache read/write"
      pattern: "DocidRrid\\.query"
---

<objective>
Add the RRID resolver function with transparent DB-level caching to service_scicrunch.py, completing the service layer.

Purpose: Enable Phase 3 blueprint to resolve any known RRID to canonical metadata with automatic 30-day caching in the DocidRrid table's resolved_json column, gracefully falling back to stale cache on SciCrunch failures.

Output: Updated `backend/app/service_scicrunch.py` with `resolve_rrid` function
</objective>

<execution_context>
@/Users/ekariz/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ekariz/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-service-layer/02-CONTEXT.md
@.planning/phases/02-service-layer/02-01-SUMMARY.md
@backend/app/models.py (DocidRrid class -- resolved_json, last_resolved_at columns)
@backend/app/service_scicrunch.py (from Plan 01 -- has session, constants, validate_rrid, search_rrid_resources)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add resolve_rrid function with 30-day DB cache and stale fallback</name>
  <files>backend/app/service_scicrunch.py</files>
  <action>
Add the following to the existing `backend/app/service_scicrunch.py` (which already has the session, constants, validate_rrid, and search_rrid_resources from Plan 01):

**Add import at top of file:**
- `from datetime import datetime, timedelta`
- `from app.models import DocidRrid`
- `from app import db`

**Add constant:**
- `CACHE_MAX_AGE_DAYS = 30` (resolver cache TTL)

**Helper function: `_normalize_resolver_response(raw_json)`**
- Extract and return ONLY the normalized subset from raw SciCrunch resolver JSON:
  ```python
  {
      "name": raw_json.get("name", ""),
      "rrid": raw_json.get("curie", ""),
      "description": raw_json.get("description", ""),
      "url": raw_json.get("url", ""),
      "resource_type": raw_json.get("resource_type", ""),
      "properCitation": raw_json.get("properCitation", ""),
      "mentions": raw_json.get("mentions", 0)
  }
  ```
  Note: The exact field paths in SciCrunch resolver JSON may vary. Use `.get()` chains defensively. The resolver URL is `https://scicrunch.org/resolver/{RRID}.json` and the response shape should be inspected. Adjust field extraction as needed to produce the normalized subset. The key requirement is that ONLY these 7 fields are stored -- not the raw blob.
- If `raw_json` is None or not a dict, return empty dict with all keys set to defaults
- Log a warning if expected fields are missing

**Function: `resolve_rrid(rrid_string, entity_type=None, entity_id=None)`**
- First, validate the RRID using `validate_rrid(rrid_string)`; if invalid, return error tuple
- Let `normalized_rrid` be the validated RRID

**Step 1 -- Check DB cache (if entity context provided):**
- If `entity_type` and `entity_id` are both provided:
  - Query `DocidRrid` for row matching `entity_type`, `entity_id`, and `rrid=normalized_rrid`
  - If row exists AND `row.last_resolved_at` is not None AND `(datetime.utcnow() - row.last_resolved_at) < timedelta(days=CACHE_MAX_AGE_DAYS)`:
    - Return `({"resolved": row.resolved_json, "last_resolved_at": row.last_resolved_at.isoformat(), "cached": True}, None)` -- fresh cache hit
  - If row exists but cache is stale or empty, keep reference to `cached_row` for fallback

**Step 2 -- Fetch from SciCrunch resolver:**
- Build URL: `f"{SCICRUNCH_RESOLVER_BASE}/resolver/{normalized_rrid}.json"`
- Use the module-level session to GET the URL
- Do NOT send `apikey` header to resolver domain (per user decision -- apikey only goes to search domain)
- Timeout: `REQUEST_TIMEOUT` seconds
- On success (HTTP 200):
  - Parse JSON response
  - Normalize via `_normalize_resolver_response()`
  - `resolved_data` = the normalized dict

**Step 3 -- Update DB cache (if entity context provided and we got fresh data):**
- If `entity_type` and `entity_id` are provided AND `resolved_data` is not empty:
  - If `cached_row` exists: update `cached_row.resolved_json = resolved_data`, `cached_row.last_resolved_at = datetime.utcnow()`
  - `db.session.commit()`
  - Log info: "Updated resolver cache for {normalized_rrid}"

**Step 4 -- Return resolved data:**
- Return `({"resolved": resolved_data, "last_resolved_at": datetime.utcnow().isoformat(), "cached": False}, None)`

**Error handling -- Stale cache fallback:**
- If the SciCrunch HTTP request fails (non-200 status or `requests.RequestException`):
  - If `cached_row` exists and `cached_row.resolved_json` is not None:
    - Log warning: "SciCrunch resolver failed, returning stale cache for {normalized_rrid}"
    - Return `({"resolved": cached_row.resolved_json, "last_resolved_at": cached_row.last_resolved_at.isoformat() if cached_row.last_resolved_at else None, "cached": True, "stale": True}, None)` -- stale cache returned
  - If no cached data exists:
    - Return `(None, {"error": "SciCrunch resolver failed", "detail": str(e) or f"HTTP {response.status_code}"})`

**Important constraints:**
- Do NOT send `apikey` header to scicrunch.org resolver (only to api.scicrunch.io search)
- `resolved_json` stores ONLY the 7 normalized fields -- not the raw blob (per CACHE-03)
- Cache TTL is exactly 30 days (per CACHE-02)
- Use `(data, error)` tuple pattern consistently
- All variable names must be declarative
- Wrap DB operations in try/except; on DB error, log and continue (resolver data still useful even if cache update fails)
  </action>
  <verify>
    <automated>cd /Users/ekariz/Projects/AMBAND/DOCiD/project && python -c "
import sys; sys.path.insert(0, 'backend');
from app.service_scicrunch import resolve_rrid, validate_rrid, search_rrid_resources, CACHE_MAX_AGE_DAYS, SCICRUNCH_RESOLVER_BASE, _normalize_resolver_response;
# Test constants
assert CACHE_MAX_AGE_DAYS == 30, 'Cache TTL must be 30 days';
assert 'scicrunch.org' in SCICRUNCH_RESOLVER_BASE;
# Test normalizer with mock data
mock_raw = {'name': 'Test', 'curie': 'SCR_012345', 'description': 'desc', 'url': 'http://test.com', 'resource_type': 'software', 'properCitation': 'cite', 'mentions': 42};
normalized = _normalize_resolver_response(mock_raw);
assert set(normalized.keys()) == {'name', 'rrid', 'description', 'url', 'resource_type', 'properCitation', 'mentions'}, f'Expected 7 keys, got {normalized.keys()}';
assert normalized['mentions'] == 42;
# Test normalizer with empty input
empty_result = _normalize_resolver_response({});
assert len(empty_result) == 7, 'Should have 7 keys even with empty input';
# Test resolve with invalid RRID
result, error = resolve_rrid('INVALID_FORMAT');
assert error is not None, 'Invalid RRID should return error';
print('ALL CHECKS PASSED')
"</automated>
    <manual>Verify resolve_rrid function exists and does not send apikey header to resolver domain</manual>
  </verify>
  <done>
- resolve_rrid function fetches from scicrunch.org/resolver/{RRID}.json
- Cached resolved_json reused when last_resolved_at is less than 30 days old
- resolved_json stores only 7 normalized fields (name, rrid, description, url, resource_type, properCitation, mentions)
- On API failure, stale cache returned if available; error only when no cache
- No apikey header sent to resolver domain
- DB cache updated transparently on successful resolve
  </done>
</task>

</tasks>

<verification>
1. `python -c "from app.service_scicrunch import resolve_rrid, validate_rrid, search_rrid_resources"` -- all three functions importable
2. `_normalize_resolver_response` produces exactly 7 keys
3. `CACHE_MAX_AGE_DAYS == 30`
4. Invalid RRID input returns error tuple without making HTTP call
5. No `apikey` in resolver request headers (grep for the pattern)
</verification>

<success_criteria>
- resolve_rrid function exists and handles cache check -> fetch -> cache update -> return flow
- 30-day TTL cache with stale fallback on API failure
- resolved_json stores normalized 7-field subset only
- All functions use (data, error) tuple return pattern
- service_scicrunch.py is complete with validate_rrid, search_rrid_resources, and resolve_rrid
</success_criteria>

<output>
After completion, create `.planning/phases/02-service-layer/02-02-SUMMARY.md`
</output>
