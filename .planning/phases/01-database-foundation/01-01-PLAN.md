---
phase: 01-database-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/models.py
  - backend/migrations/versions/xxxx_add_docid_rrids_table.py
autonomous: true
requirements:
  - INFRA-01
  - INFRA-02
  - INFRA-03
  - INFRA-04
must_haves:
  truths:
    - "Running `flask db upgrade` creates a `docid_rrids` table with all 12 columns"
    - "Attempting to insert two rows with identical (entity_type, entity_id, rrid) raises a UniqueConstraint violation"
    - "A query plan for `SELECT * FROM docid_rrids WHERE entity_type = 'publication' AND entity_id = 1` uses the composite index"
    - "`DocidRrid.serialize()` returns a Python dict with all model fields"
    - "`DocidRrid.get_rrids_for_entity('publication', 1)` returns a list of DocidRrid instances"
    - "`DocidRrid.get_by_rrid('RRID:SCR_012345')` returns a DocidRrid instance or None"
  artifacts:
    - path: "backend/app/models.py"
      provides: "DocidRrid SQLAlchemy model class"
      contains: "class DocidRrid"
    - path: "backend/migrations/versions/xxxx_add_docid_rrids_table.py"
      provides: "Alembic migration creating docid_rrids table"
      contains: "create_table"
  key_links:
    - from: "backend/app/models.py"
      to: "docid_rrids PostgreSQL table"
      via: "SQLAlchemy model-to-table mapping"
      pattern: "__tablename__ = 'docid_rrids'"
    - from: "backend/migrations/versions/xxxx_add_docid_rrids_table.py"
      to: "backend/app/models.py"
      via: "Alembic autogenerate reads model metadata"
      pattern: "op.create_table\\('docid_rrids'"
---

<objective>
Create the `DocidRrid` SQLAlchemy model and Alembic migration that establishes the `docid_rrids` PostgreSQL table with all columns, constraints, indexes, and query helpers.

Purpose: Every subsequent RRID integration phase (service layer, blueprint, frontend) depends on this table and model existing. This is the foundation layer.
Output: `DocidRrid` model class in `models.py` and a working Alembic migration that creates the table with seed data.
</objective>

<execution_context>
@/Users/ekariz/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ekariz/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-database-foundation/01-CONTEXT.md
@.planning/research/ARCHITECTURE.md
@.planning/research/STACK.md
@.planning/research/PITFALLS.md
@backend/app/models.py
@backend/migrations/versions/4e67049fd9a2_add_account_types_table_and_account_.py
@backend/CLAUDE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add DocidRrid model to models.py</name>
  <files>backend/app/models.py</files>
  <action>
Add the `DocidRrid` model class to `backend/app/models.py` AFTER the `LocalContextAuditLog` class (end of file). This is the last model in the file, so append after it.

Add the JSONB import at the top of the file alongside existing imports:
```python
from sqlalchemy.dialects.postgresql import JSONB
```

Add the model class with these exact specifications (per user decisions in CONTEXT.md):

**Columns (in this order):**
- `id`: `db.Column(db.Integer, primary_key=True, autoincrement=True)`
- `entity_type`: `db.Column(db.String(50), nullable=False)` -- stores 'publication' or 'organization'
- `entity_id`: `db.Column(db.Integer, nullable=False)` -- matches publications.id or publication_organizations.id
- `rrid`: `db.Column(db.String(50), nullable=False)` -- RRID curie format e.g. RRID:SCR_012345
- `rrid_name`: `db.Column(db.String(500), nullable=True)` -- facility/resource name from SciCrunch
- `rrid_description`: `db.Column(db.Text, nullable=True)` -- resource description
- `rrid_resource_type`: `db.Column(db.String(100), nullable=True)` -- e.g. 'core facility', 'software'
- `rrid_url`: `db.Column(db.String(500), nullable=True)` -- resource URL
- `resolved_json`: `db.Column(JSONB, nullable=True)` -- cached resolver metadata (normalized subset only)
- `last_resolved_at`: `db.Column(db.DateTime, nullable=True)` -- when resolver cache was last refreshed
- `created_at`: `db.Column(db.DateTime, default=datetime.utcnow, nullable=False)` -- use server_default pattern if consistent with codebase, otherwise datetime.utcnow
- `updated_at`: `db.Column(db.DateTime, nullable=True, onupdate=datetime.utcnow)` -- auto-updates on change

**Table args (constraints and indexes):**
```python
__table_args__ = (
    db.UniqueConstraint('entity_type', 'entity_id', 'rrid', name='uq_docid_rrids_entity_rrid'),
    db.Index('ix_docid_rrids_entity_lookup', 'entity_type', 'entity_id'),
)
```

**Set `__tablename__` explicitly:**
```python
__tablename__ = 'docid_rrids'
```

**No SQLAlchemy `relationship()` declarations** -- polymorphic entity_id prevents clean FK relationships. Query by ID using class methods instead. (Per user decision.)

**Class methods (follow PublicationComments pattern):**

1. `get_rrids_for_entity(cls, entity_type, entity_id)` -- classmethod returning `cls.query.filter_by(entity_type=entity_type, entity_id=entity_id).order_by(cls.created_at.desc()).all()`

2. `get_by_rrid(cls, rrid_value)` -- classmethod returning `cls.query.filter_by(rrid=rrid_value).first()`

**`serialize()` method** -- returns a dict with ALL 12 fields. Use `.isoformat()` for datetime fields (with None guard). Include `resolved_json` inline (already a small normalized subset per user decision).

**`__repr__` method:**
```python
def __repr__(self):
    return f"<DocidRrid(id={self.id}, entity={self.entity_type}:{self.entity_id}, rrid='{self.rrid}')>"
```

**Add section comment before the class** following the existing pattern in models.py:
```python
# ==============================================================================
# RRID (Research Resource Identifier) Integration Model
# Dedicated association table for RRID attachments to publications and organizations
# ==============================================================================
```

Do NOT add the `resolve_entity` helper function in this task -- that belongs in the blueprint phase (Phase 4) where it will be used for entity validation before attachment.
  </action>
  <verify>
    <automated>cd /Users/ekariz/Projects/AMBAND/DOCiD/project/backend && python -c "from app.models import DocidRrid; r = DocidRrid(); print('serialize keys:', list(r.serialize().keys())); print('class methods:', [m for m in dir(DocidRrid) if not m.startswith('_') and callable(getattr(DocidRrid, m))])"</automated>
    <manual>Verify DocidRrid class is at the end of models.py, has all 12 columns, UniqueConstraint, composite index, serialize(), get_rrids_for_entity(), get_by_rrid()</manual>
  </verify>
  <done>
    - DocidRrid class exists in models.py with all 12 columns matching CONTEXT.md specs
    - JSONB import added from sqlalchemy.dialects.postgresql
    - UniqueConstraint named 'uq_docid_rrids_entity_rrid' on (entity_type, entity_id, rrid)
    - Composite index named 'ix_docid_rrids_entity_lookup' on (entity_type, entity_id)
    - serialize() returns dict with all 12 fields
    - get_rrids_for_entity() and get_by_rrid() class methods work
    - No relationship() declarations (per user decision)
    - Model placed after LocalContextAuditLog at end of file
  </done>
</task>

<task type="auto">
  <name>Task 2: Generate Alembic migration with CHECK constraint and seed data</name>
  <files>backend/migrations/versions/xxxx_add_docid_rrids_table.py</files>
  <action>
Generate the Alembic migration from the model added in Task 1, then review and adjust it.

**Step 1: Generate migration**
```bash
cd /Users/ekariz/Projects/AMBAND/DOCiD/project/backend
python run.py db migrate -m "add docid_rrids table"
```

**Step 2: Review and adjust the generated migration file.** Open the newly created file in `backend/migrations/versions/` (the one with `_add_docid_rrids_table.py` suffix). Ensure it contains:

1. **All 12 columns** with correct types:
   - id (Integer, PK)
   - entity_type (String(50), NOT NULL)
   - entity_id (Integer, NOT NULL)
   - rrid (String(50), NOT NULL)
   - rrid_name (String(500), nullable)
   - rrid_description (Text, nullable)
   - rrid_resource_type (String(100), nullable)
   - rrid_url (String(500), nullable)
   - resolved_json (JSONB, nullable) -- use `sa.dialects.postgresql.JSONB()` or import separately
   - last_resolved_at (DateTime, nullable)
   - created_at (DateTime, NOT NULL)
   - updated_at (DateTime, nullable)

2. **Add CHECK constraint for entity_type** (per user decision: both DB-level CHECK AND Python validation):
   Add after `op.create_table(...)`:
   ```python
   op.execute("ALTER TABLE docid_rrids ADD CONSTRAINT ck_docid_rrids_entity_type CHECK (entity_type IN ('publication', 'organization'))")
   ```

3. **Verify composite index** with explicit name `ix_docid_rrids_entity_lookup` on (entity_type, entity_id) is present. Alembic autogenerate should pick this up from the model's `__table_args__`.

4. **Verify UniqueConstraint** with explicit name `uq_docid_rrids_entity_rrid` on (entity_type, entity_id, rrid) is present.

5. **Add seed data** (per user decision: 2-3 sample RRID records for development testing):
   Add after table creation and constraints:
   ```python
   # Seed sample RRID records for development testing
   # These use real RRID values from SciCrunch
   docid_rrids_table = sa.table('docid_rrids',
       sa.column('entity_type', sa.String),
       sa.column('entity_id', sa.Integer),
       sa.column('rrid', sa.String),
       sa.column('rrid_name', sa.String),
       sa.column('rrid_resource_type', sa.String),
       sa.column('rrid_url', sa.String),
       sa.column('created_at', sa.DateTime),
   )
   op.bulk_insert(docid_rrids_table, [
       {
           'entity_type': 'publication',
           'entity_id': 1,
           'rrid': 'RRID:SCR_002285',
           'rrid_name': 'ImageJ',
           'rrid_resource_type': 'software',
           'rrid_url': 'https://imagej.net/',
           'created_at': sa.func.now(),
       },
       {
           'entity_type': 'publication',
           'entity_id': 1,
           'rrid': 'RRID:SCR_003070',
           'rrid_name': 'Fiji',
           'rrid_resource_type': 'software',
           'rrid_url': 'https://fiji.sc/',
           'created_at': sa.func.now(),
       },
       {
           'entity_type': 'organization',
           'entity_id': 1,
           'rrid': 'RRID:SCR_011211',
           'rrid_name': 'African Academy of Sciences',
           'rrid_resource_type': 'core facility',
           'rrid_url': 'https://www.aasciences.africa/',
           'created_at': sa.func.now(),
       },
   ])
   ```
   Note: If `sa.func.now()` does not work inside `bulk_insert`, replace with `datetime.utcnow()` after importing `from datetime import datetime` at the top of the migration file.

6. **Full downgrade path** (per user decision: follows existing DOCiD migration patterns):
   ```python
   def downgrade():
       op.execute("ALTER TABLE docid_rrids DROP CONSTRAINT IF EXISTS ck_docid_rrids_entity_type")
       op.drop_table('docid_rrids')
   ```

**Step 3: Apply the migration**
```bash
cd /Users/ekariz/Projects/AMBAND/DOCiD/project/backend
python run.py db upgrade
```

**Step 4: Verify the table exists and constraints work**
Run a quick verification:
```bash
cd /Users/ekariz/Projects/AMBAND/DOCiD/project/backend
python -c "
from app import create_app, db
from app.models import DocidRrid
app = create_app()
with app.app_context():
    # Verify table exists by counting rows
    count = DocidRrid.query.count()
    print(f'docid_rrids table exists with {count} rows (should be 3 from seed data)')

    # Verify columns via serialize
    first = DocidRrid.query.first()
    if first:
        keys = list(first.serialize().keys())
        print(f'Columns in serialize: {keys}')
        print(f'Column count: {len(keys)} (should be 12)')

    # Verify class methods
    rrids = DocidRrid.get_rrids_for_entity('publication', 1)
    print(f'get_rrids_for_entity publication 1: {len(rrids)} rows (should be 2)')

    by_rrid = DocidRrid.get_by_rrid('RRID:SCR_002285')
    print(f'get_by_rrid SCR_002285: {by_rrid}')
"
```
  </action>
  <verify>
    <automated>cd /Users/ekariz/Projects/AMBAND/DOCiD/project/backend && python -c "
from app import create_app, db
from sqlalchemy import text, inspect
app = create_app()
with app.app_context():
    # 1. Table exists with all columns
    inspector = inspect(db.engine)
    columns = [c['name'] for c in inspector.get_columns('docid_rrids')]
    assert len(columns) == 12, f'Expected 12 columns, got {len(columns)}: {columns}'
    print(f'PASS: 12 columns found: {columns}')

    # 2. Unique constraint exists
    uqs = inspector.get_unique_constraints('docid_rrids')
    uq_names = [u['name'] for u in uqs]
    assert 'uq_docid_rrids_entity_rrid' in uq_names, f'UniqueConstraint missing: {uq_names}'
    print(f'PASS: UniqueConstraint uq_docid_rrids_entity_rrid exists')

    # 3. Composite index exists
    indexes = inspector.get_indexes('docid_rrids')
    idx_names = [i['name'] for i in indexes]
    assert 'ix_docid_rrids_entity_lookup' in idx_names, f'Composite index missing: {idx_names}'
    print(f'PASS: Composite index ix_docid_rrids_entity_lookup exists')

    # 4. CHECK constraint exists
    result = db.session.execute(text(\"\"\"
        SELECT conname FROM pg_constraint
        WHERE conrelid = 'docid_rrids'::regclass AND contype = 'c'
    \"\"\")).fetchall()
    check_names = [r[0] for r in result]
    assert 'ck_docid_rrids_entity_type' in check_names, f'CHECK constraint missing: {check_names}'
    print(f'PASS: CHECK constraint ck_docid_rrids_entity_type exists')

    # 5. Seed data present
    from app.models import DocidRrid
    count = DocidRrid.query.count()
    assert count >= 3, f'Expected >= 3 seed rows, got {count}'
    print(f'PASS: {count} seed rows present')

    # 6. EXPLAIN uses index
    result = db.session.execute(text(\"\"\"
        EXPLAIN SELECT * FROM docid_rrids WHERE entity_type = 'publication' AND entity_id = 1
    \"\"\")).fetchall()
    plan = ' '.join([r[0] for r in result])
    print(f'Query plan: {plan}')
    # Index usage may show as Index Scan or Bitmap Index Scan

    print('ALL CHECKS PASSED')
"</automated>
    <manual>Verify migration file exists in backend/migrations/versions/ with correct columns, constraints, and seed data</manual>
  </verify>
  <done>
    - Alembic migration file created and applied successfully
    - `docid_rrids` table exists in PostgreSQL with all 12 columns
    - CHECK constraint `ck_docid_rrids_entity_type` enforces entity_type IN ('publication', 'organization')
    - UniqueConstraint `uq_docid_rrids_entity_rrid` prevents duplicate RRID per entity
    - Composite index `ix_docid_rrids_entity_lookup` on (entity_type, entity_id) for fast lookups
    - 3 seed RRID records present for development testing
    - Full downgrade path drops constraint and table
    - `flask db upgrade` and `flask db downgrade` both work cleanly
  </done>
</task>

</tasks>

<verification>
After both tasks complete, verify the full Phase 1 success criteria from ROADMAP.md:

1. **`flask db upgrade` creates `docid_rrids` table** with all 12 columns (id, entity_type, entity_id, rrid, rrid_name, rrid_description, rrid_resource_type, rrid_url, resolved_json, last_resolved_at, created_at, updated_at)
2. **UniqueConstraint violation** when inserting duplicate (entity_type, entity_id, rrid) -- test by trying to insert two identical rows
3. **Composite index used** by `EXPLAIN` for entity-scoped queries
4. **`DocidRrid.serialize()`** returns dict with all model fields
5. **CHECK constraint** rejects entity_type values outside {'publication', 'organization'}
6. **Seed data** present for development testing
</verification>

<success_criteria>
- `DocidRrid` model class exists at end of `backend/app/models.py` with 12 columns, 2 class methods, serialize(), and section comment
- JSONB import from `sqlalchemy.dialects.postgresql` present
- Alembic migration file exists and has been applied
- `docid_rrids` table has UniqueConstraint, composite index, and CHECK constraint at DB level
- 3 seed records present in table
- Migration is fully reversible (downgrade drops table and constraint)
- No relationship() declarations on the model (per user decision)
</success_criteria>

<output>
After completion, create `.planning/phases/01-database-foundation/01-01-SUMMARY.md`
</output>
